# -*- coding: utf-8 -*-
"""Q2_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R-h6mR7sy_h7Yi1dKE4xCb8nKprgkVDj
"""
import time
import itertools
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from linearRegression.linear_regression import LinearRegression
from metrics import *
from sklearn.model_selection import train_test_split

np.random.seed(45)

N=60
base_vals=np.array([i*np.pi/180 for i in range(60,300,2)])
X = pd.DataFrame(base_vals)
y = 3*(base_vals) + 8 + np.random.normal(0,3,len(X))


print('Batch Gradient descent ')

batchsize = 30
lr=[1e-5,5e-3,0.1]
type_=['jax','manual']
num_iters=[1,5,50]
penalties = [None, 'l2']

time_arr=[]
rmse_arr=[]
mae_arr=[]
final_list=[]

for grad_type,iterations,learning_rate, penalty_type in list(itertools.product(type_, num_iters, lr, penalties)):

    LR_ = LinearRegression(fit_intercept=True)
    LR_.intercept_=0
    LR_.coef_=np.zeros(X.shape[1])
    t1=time.time()
    LR_.fit_gradient_descent(X.copy(),y.copy(),batchsize, grad_type, penalty_type, num_iters=iterations, lr=learning_rate)
    t2=time.time()

    # print("-----------------------------------------------------------------------------------")
    #print(grad_type, iterations, learning_rate, penalty_type)
    
    y_hat = LR_.predict(X)

    time_arr.append(t2-t1)
    rmse_arr.append(rmse(y_hat, y))
    mae_arr.append(mae(y_hat, y))
    final_list.append((grad_type,iterations,learning_rate, penalty_type,t2-t1,rmse(y_hat, y),mae(y_hat, y)))
    #print(' Batch size=',batchsize,', RMSE: ', rmse(y_hat, y))
    #print(' Batch size=',batchsize,', MAE: ', mae(y_hat, y))

df = pd.DataFrame.from_records(final_list, columns =['Grad Type', 'Iteration Number', 'Lr','Penalty type','Time','RMSE','MAE'])
df.to_csv('/home/divyanshu/Documents/Academics/Sem8/Machine Learning/Assignment4/Q2_csv/batch.csv')
print(df)


print("-----------------------------------------------------------------------------------")

print('SGD with momentum ')

num_iters = [1,5,50]
lr=[1e-5,5e-3,0.1]
penalties = [None, 'l2']
beta = [0.8, 100]

time_arr=[]
rmse_arr=[]
mae_arr=[]
final_list=[]

for iterations,learning_rate, penalty_type, beta_ in list(itertools.product(num_iters, lr, penalties, beta)):

    LR_ = LinearRegression(fit_intercept=True)
    LR_.intercept_=0
    LR_.coef_=np.zeros(X.shape[1])
    t1=time.time()
    LR_.fit_SGD_with_momentum(X.copy(),y.copy(),num_iters=90,lr=0.05,penalty='l2', beta=0.8)
    t2=time.time()

    #print("-----------------------------------------------------------------------------------")
    #print(grad_type, iterations, learning_rate, penalty_type)
    
    y_hat = LR_.predict(X)

    time_arr.append(t2-t1)
    rmse_arr.append(rmse(y_hat, y))
    mae_arr.append(mae(y_hat, y))
    final_list.append((iterations,learning_rate, penalty_type, beta_, t2-t1,rmse(y_hat, y),mae(y_hat, y)))
    #print(' Batch size=',batchsize,', RMSE: ', rmse(y_hat, y))
    #print(' Batch size=',batchsize,', MAE: ', mae(y_hat, y))

df = pd.DataFrame.from_records(final_list, columns =['Iteration Number', 'Lr','Penalty type', 'Beta','Time','RMSE','MAE'])
df.to_csv('/home/divyanshu/Documents/Academics/Sem8/Machine Learning/Assignment4/Q2_csv/sgd.csv')
print(df)